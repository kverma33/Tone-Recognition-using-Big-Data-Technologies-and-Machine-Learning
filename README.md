# Tone-Recognition-using-Big-Data-Technologies-and-Machine-Learning

Overview:
This is an attempt to determine a person's tone based on his or her tweets. We use machine learning models for tone recognition, and because the data is so large, we use big data technology. Sagemaker and spark mlib are two big data technologies involved. We are using RoBerta and RNN to train the model that can detect a person's tone from tweets.

Sagemaker:

Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. Amazon SageMaker automatic model tuning can use Amazon EC2 Spot instance to optimize costs when running training jobs. Before you start using hyperparameter tuning, you should have a well-defined machine learning problem, including the following:
• A dataset
• An understanding of the type of algorithm you need to train
• A clear understanding of how you measure success


The complete machine learning pipeline, including labeling and prepping data, selecting an algorithm, training the model, fine-tuning and optimizing it for deployment, making predictions, and taking action, is covered by the fully-managed service Amazon SageMaker.


RoBerta:

RoBERTa(Robustly Optimized BERT pre-training Approach) expands on the BERT model architecture while changing some model hyperparameters and the model's training process, including the use of more training data. In contrast to BERT, this can actually result in notable performance gains in a number of NLP tasks.


RNN:

The most fundamental and potent neural networks are recurrent neural networks (RNN). These algorithms have gained a lot of popularity since they have produced promising outcomes for several technologies. RNN's main goal is to process sequential data effectively. The idea of internal memory sets RNN apart from conventional neural networks.
Recurrent neural networks are somewhat more established than other types of neural networks, having existed since the 1980s, although recently gaining popularity. With the advancement of technology, RNN has taken the lead because we now have greater computing power and a lot of data that has been collected recently.


